%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Plik: poster.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[a1paper,portrait,fontscale=0.54]{baposter}

% --- MARGINS ---
\geometry{top=2cm, bottom=2.5cm, left=1cm, right=1cm}
\setlength{\voffset}{1cm}
% ----------------------------------

% Encoding and fonts for proper Polish diacritics
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{amssymb, mathtools, amsmath}
\usepackage{multicol}
\usepackage{caption}
\usepackage{array,booktabs}
\usepackage{pgfplots}
\usepackage{enumitem}
\usepackage{url}
\usepackage{xcolor}

% --- Ustawienia kolorów ---
\selectcolormodel{RGB}
\definecolor{nustblue}{RGB}{0,102,158}
\definecolor{nustblue1}{RGB}{0, 189, 181} 
\definecolor{nustblue2}{RGB}{0,153,237}

% --- Ustawienia list ---
\setlist{nosep, leftmargin=*, labelindent=0pt, font=\color{nustblue}\bfseries}

% --- Ścieżki do grafik ---
\graphicspath{{images/}{images/logos/}{images/adversarial_examples/}{images/results/}}
\setkeys{Gin}{draft=false} 

% --- Ustawienia podpisów ---
\captionsetup{font=small, labelfont={bf}}

\begin{document}

% --- TŁO: Czysta biel ---
\background{} 

% --- Konfiguracja Plakatu ---
\begin{poster}{
  grid=false,
  columns=3,
  colspacing=4mm,
  headerheight=0.14\textheight,
  background=plain,
  bgColorOne=white,
  eyecatcher=true,
  headerborder=closed,
  borderColor=nustblue,
  headershape=rectangle,
  headershade=plain,
  headerColorOne=nustblue,
  headerFontColor=white,
  headerfont=\Large\bfseries\sffamily,
  textborder=rectangle,
  boxshade=plain,
  boxColorOne=white,
  linewidth=1pt
}
% --- Logo Lewe ---
{
   \begin{minipage}[c]{0.15\textwidth}
     \centering
     \includegraphics[height=0.22\headerheight]{images/logos/UWr_Logo.jpg} \\
     \vspace{0.2em}
     \includegraphics[height=0.20\headerheight]{images/logos/KSI_Logo.png} \\
     \vspace{0.2em}
     \includegraphics[height=0.18\headerheight]{images/logos/Arqus.png}
     \vspace{0.2em}
     \includegraphics[height=0.18\headerheight]{images/logos/Research_University_Horizontal.png}
   \end{minipage}
}
% --- Tytuł ---
{\color{nustblue}\bf
\Huge DINOmite: Adversarial Robustness \\of DINOv3 Vision Transformers
}
% --- Subtitle: Authors (alphabetical by surname) ---
{\color{black}\large
  \vspace{0.8em}
    \centering Wojciech Aszkie\l{}owicz$^*$ \;\; Hubert Berlicki$^*$ \;\; Jan Burdzicki$^*$ \;\; Igor Jakus$^*$ \\[0.4em]
  {\small w.aszkielowicz@proton.me \;\; berlickihubert@gmail.com \;\; janburdzicki@gmail.com \;\; igorjakus@protonmail.com} \\[0.5em]
    Institute of Computer Science, University of Wroc\l{}aw \\[0.3em]
  {\small $^*$Equal contribution}
}
% --- Logo Prawe ---
{
  \vspace{0.5em}
  \includegraphics[height=1\headerheight]{images/logos/qrcode.png}
}

% ============================================================================
% REFERENCJE (Kotwica na dole)
% ============================================================================
\begin{posterbox}[name=references, column=0, span=3, above=bottom]{References}
\begin{enumerate}
    \item Goodfellow et al. (2015). \textit{Explaining and Harnessing Adversarial Examples}. arXiv:1412.6572
    \item Moosavi-Dezfooli et al. (2016). \textit{DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks}. arXiv:1511.04599
    \item Madry et al. (2018). \textit{Towards Deep Learning Models Resistant to Adversarial Attacks}. arXiv:1706.06083
    \item Carlini \& Wagner (2017). \textit{Towards Evaluating the Robustness of Neural Networks}. arXiv:1608.04644
    \item Zhang et al. (2019). \textit{Theoretically Principled Trade-off between Robustness and Accuracy}. arXiv:1901.08573
    \item Kurakin et al. (2017). \textit{Adversarial Examples in the Physical World}. arXiv:1607.02533
    \item Wang et al. (2020). \textit{Improving Adversarial Robustness Requires Revisiting Data Augmentation and Training}. OpenReview: rklOg6EFwS
\end{enumerate}
\end{posterbox}

% ============================================================================
% KOLUMNA 1 (Left)
% Abstract -> Motivation -> Problem -> Experiments -> Conclusions
% ============================================================================

\begin{posterbox}[name=abstract, column=0, row=0]{Abstract}
\textbf{Problem:} DINOv3 Vision Transformers achieve state-of-the-art accuracy but remain vulnerable to adversarial attacks.

\textbf{Contribution:} We present a comprehensive evaluation framework for DINOv3, testing robustness against gradient-based and optimization-based attacks. We compare standard fine-tuning against advanced adversarial defense strategies.
\end{posterbox}

\begin{posterbox}[name=motivation, column=0, below=abstract]{Motivation}
\subsection*{Why It Matters}
\begin{itemize}
    \item \textbf{Safety-Critical Systems:} Autonomous driving, medical imaging.
    \item \textbf{Physical Threats:} Adversarial patches work in reality.
\end{itemize}

\subsection*{Research Questions}
\begin{enumerate}
    \item Does self-supervised DINOv3 offer inherent robustness?
    \item Which defense strategy minimizes the accuracy trade-off?
\end{enumerate}
\end{posterbox}

\begin{posterbox}[name=problem, column=0, below=motivation]{Problem Definition}
We formulate the attack as a constrained optimization problem:
$$ \max_{\delta} L(f(x + \delta), y) \quad \text{s.t.} \quad \|\delta\|_\infty \leq \epsilon $$

\subsection*{Threat Model}
\begin{itemize}
    \item \textbf{White-box:} Full access to gradients.
    \item \textbf{Constraint:} $\epsilon = 8/255$.
    \item \textbf{Goal:} Untargeted misclassification.
\end{itemize}
\end{posterbox}

% PRZENIESIONE: Experimental Setup
\begin{posterbox}[name=experiments, column=0, below=problem]{Experimental Setup}
\subsection*{Model Architecture}
\begin{itemize}
    \item \textbf{Backbone:} DINOv3 ViT-S/16 (Frozen).
    \item \textbf{Head:} Linear Classification Head (Trainable).
\end{itemize}

\subsection*{Datasets}
\begin{itemize}
    \item \textbf{CIFAR-10:} Primary benchmark.
    \item \textbf{GTSRB:} Traffic signs (Safety-critical).
\end{itemize}

\subsection*{Evaluation}
\begin{itemize}
    \item \textbf{Metric:} Clean vs. Robust Accuracy (PGD-10).
    \item \textbf{Epsilon:} $\epsilon \in \{0, \dots, 8/255\}$.
\end{itemize}
\end{posterbox}

\begin{posterbox}[name=conclusions, column=0, below=experiments, above=references]{Conclusions}
\subsection*{Main Takeaways}
\begin{itemize}
    \item \textbf{Vulnerability:} DINOv3 has no inherent robustness against gradient attacks.
    \item \textbf{Defense:} TRADES successfully recovers 60\% accuracy under strong PGD attacks.
    \item \textbf{Trade-off:} The robustness gain justifies the small drop in clean accuracy.
\end{itemize}

\subsection*{Future Work}
\begin{itemize}
    \item Evaluating Certified Robustness.
    \item Scaling to ImageNet-1k.
    \item Testing diverse attack methods (e.g., AutoAttack).
    \item Exploring advanced defenses (e.g., MART).
\end{itemize}
\end{posterbox}

% ============================================================================
% KOLUMNA 2 (Center)
% Attack Methods -> Adversarial Examples
% ============================================================================

\begin{posterbox}[name=attacks, column=1, row=0]{Attack Methods}
We focus on three primary attack vectors representing different threat levels:

\subsection*{FGSM (Fast Gradient Sign Method)}
A single-step attack assuming linear loss surface.
$$ x_{adv} = x + \epsilon \cdot \text{sign}(\nabla_x L(\theta, x, y)) $$
\textit{Note: Fast, but weak against iterative training.}

\subsection*{PGD (Projected Gradient Descent)}
The "Universal First-Order Adversary". Iterative FGSM with projection.
$$ x^{t+1} = \Pi_{x+\mathcal{S}} (x^t + \alpha \cdot \text{sign}(\nabla_x L(\theta, x^t, y))) $$
\textit{Note: The strongest defense benchmark. We use 10 steps.}

\subsection*{C\&W (Carlini \& Wagner)}
Optimization-based attack minimizing distance and loss term.
$$ \min_{\delta} \|\delta\|_2 + c \cdot f(x+\delta) $$
\textit{Note: Finds adversarial examples with minimal visible perturbation.}
\end{posterbox}

\begin{posterbox}[name=examples, column=1, below=attacks, above=references]{Adversarial Examples}
\centering
\textbf{C\&W ($L_2$)} - Minimal Perturbation
\includegraphics[width=0.95\linewidth]{images/adversarial_examples/cw_example_cifar10_1.png}\\
\vspace{1em}

\centering
\textbf{FGSM ($\epsilon=8/255$)} - Patterned Noise
\includegraphics[width=0.95\linewidth]{images/adversarial_examples/fgsm_example_cifar10_2.png}\\
\vspace{1em}

\centering
\textbf{PGD ($\epsilon=8/255$)} - High Noise
\includegraphics[width=0.95\linewidth]{images/adversarial_examples/pgd_example_cifar10_3.png}\\
\end{posterbox}

% ============================================================================
% KOLUMNA 3 (Right)
% Defenses -> Results -> Comparison -> Curves
% ============================================================================

% PRZENIESIONE: Defense Strategies
\begin{posterbox}[name=defenses, column=2, row=0]{Defense Strategies}
Standard training yields 0\% robustness. We evaluate three state-of-the-art defenses:

\subsection*{PGD-AT (Adversarial Training)}
Min-Max game training on PGD examples.
$$ \min_\theta \mathbb{E} [\max_{\delta \in S} L(f(x+\delta), y)] $$

\subsection*{TRADES}
Separates clean accuracy and stability (KL-divergence).
$$ \min_\theta \mathbb{E} [L(f(x),y) + \beta \cdot \text{KL}(f(x) \| f(x+\delta_{adv}))] $$
\textit{Result: Smoother decision boundaries.}
\end{posterbox}

\begin{posterbox}[name=comparison, column=2, below=defenses]{Defense Results}
\centering
\includegraphics[width=0.95\linewidth]{images/results/accuracy_plot_trades.png}
\includegraphics[width=0.95\linewidth]{images/results/accuracy_plot_pgd-at.png}
\captionof{figure}{Robustness and accuracy across defense methods.}
\end{posterbox}

\begin{posterbox}[name=results, column=2, below=comparison]{Quantitative Results}
Comparison on CIFAR-10 ($\epsilon=8/255$).

\begin{center}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Clean} & \textbf{FGSM} & \textbf{PGD} \\
\midrule
Standard & \textbf{85.0\%} & 45.0\% & 25.0\% \\
PGD-AT & 82.0\% & 65.0\% & 55.0\% \\
TRADES & 81.5\% & \textbf{68.0\%} & \textbf{60.0\%} \\
\bottomrule
\end{tabular}
\end{center}
\end{posterbox}

\end{poster}
\end{document}